import requests
from bs4 import BeautifulSoup
from datetime import datetime

def fetch_kyobo_best_sellers():
    url = "https://www.kyobobook.co.kr/bestseller/online"
    headers = {"User-Agent": "Mozilla/5.0"}

    response = requests.get(url, headers=headers)
    soup = BeautifulSoup(response.text, "html.parser")

    books = []
    for idx, item in enumerate(soup.select("div.detail"), start=1):
        title_tag = item.select_one("div.title")
        author_tag = item.select_one("div.author")

        if title_tag and author_tag:
            title = title_tag.text.strip()
            author = author_tag.text.strip().replace('\n', '').replace('ì €ì ë”ë³´ê¸°', '')
            books.append(f"{idx}. **{title}** - _{author}_")

        if idx >= 20:  # ìƒìœ„ 20ê¶Œë§Œ ì¶œë ¥
            break

    return books

def update_readme(books):
    now = datetime.now().strftime("%Y-%m-%d %H:%M")
    content = f"# ğŸ“š êµë³´ë¬¸ê³  ë² ìŠ¤íŠ¸ì…€ëŸ¬ (ì—…ë°ì´íŠ¸: {now})\n\n"
    if books:
        content += "\n".join(books)
    else:
        content += "â—ï¸ë² ìŠ¤íŠ¸ì…€ëŸ¬ ì •ë³´ë¥¼ ë¶ˆëŸ¬ì˜¤ì§€ ëª»í–ˆìŠµë‹ˆë‹¤."

    content += "\n\nìë™ ì—…ë°ì´íŠ¸: GitHub Actions ì‚¬ìš©"

    with open("README.md", "w", encoding="utf-8") as f:
        f.write(content)

if __name__ == "__main__":
    best_sellers = fetch_kyobo_best_sellers()
    update_readme(best_sellers)
