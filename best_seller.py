import requests
from bs4 import BeautifulSoup
from datetime import datetime

def fetch_aladin_rss_bestsellers():
    url = "https://www.aladin.co.kr/rsscenter/rss_feeds.aspx?cid=0&type=Bestseller"
    response = requests.get(url)
    soup = BeautifulSoup(response.content, "xml")

    books = []
    for idx, item in enumerate(soup.find_all("item")[:20], start=1):
        title = item.title.text.strip()
        link = item.link.text.strip()
        books.append(f"{idx}. [{title}]({link})")

    return books

def update_readme(books):
    now = datetime.now().strftime("%Y-%m-%d %H:%M")
    content = f"# ğŸ“š ì•Œë¼ë”˜ ë² ìŠ¤íŠ¸ì…€ëŸ¬ (ì—…ë°ì´íŠ¸: {now})\n\n"

    if books:
        content += "\n".join(books)
    else:
        content += "â—ï¸ë² ìŠ¤íŠ¸ì…€ëŸ¬ ì •ë³´ë¥¼ ë¶ˆëŸ¬ì˜¤ì§€ ëª»í–ˆìŠµë‹ˆë‹¤."

    content += "\n\nìë™ ì—…ë°ì´íŠ¸: GitHub Actions ì‚¬ìš©"

    with open("README.md", "w", encoding="utf-8") as f:
        f.write(content)

if __name__ == "__main__":
    books = fetch_aladin_rss_bestsellers()
    update_readme(books)
